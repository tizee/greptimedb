searchState.loadedDescShard("object_store", 0, "The accessor that built by this builder.\nThe given path already exists thus we failed to the …\nKey for cache control.\nThe special metadata key that used to mark this entry …\nThe condition of this operation is not match.\nThe config for backend is invalid.\nKey for content disposition.\nThe content is incomplete.\nKey for content length.\nKey for content md5.\nKey for content range.\nThe content is truncated.\nKey for content type.\nDIR means the path can be listed.\nEntry returned by <code>Lister</code> or <code>BlockingLister</code> to represent a …\nEntryMode represents the mode.\nContains the error value\nError is the error struct returned by all opendal …\nErrorKind is all kinds of Error of opendal.\nKey for etag.\nFILE means the path has data to read.\nHttpClient that used across opendal.\nThe input is invalid.\nThe given path is a directory.\nThe given file paths are same.\nKey for last modified.\nLister is designed to list entries at given path in an …\nMetakey describes the metadata keys that can be stored or …\nKey for mode.\nThe given path is not a directory.\nThe given path is not found.\nOperator is the entry for all public async APIs.\nBuilder is used to set up a real underlying service, i.e. …\nContains the success value\nThe given path doesn’t have enough permission for this …\nRequests that sent to this path is over the limit, please …\nReader is designed to read data from given path in an …\nResult that is a wrapper of <code>Result&lt;T, opendal::Error&gt;</code>\nAssociated scheme for this builder. It indicates what …\nOpenDAL don’t know what happened here, and no actions …\nUnknown means we don’t know what we can do on this path.\nUnderlying service doesn’t support this operation.\nKey for version.\nWriter is designed to write data into given path in an …\nAbort the writer and clean up all written data.\nCreate a new blocking operator.\nConsume the accessor builder to build a service.\nBuild a new http client in async context.\nCheck if this operator can work correctly.\nGet the async client from http client.\nClose the writer and make sure all data have been …\nCopy into writer.\nCopy a file from <code>from</code> to <code>to</code>.\nCreate a dir at given path.\nDelete the given path.\nDelete the given path with extra options.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nConstruct a builder from given map which contains several …\nCreate a new operator from given map.\nGet information of underlying accessor.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConsume this entry to get it’s path and metadata.\nConvert self into static str.\nCheck if this mode is DIR.\nCheck if this path exists or not.\nCheck if this mode is FILE.\nCheck if this error is temporary.\nReturn error’s kind.\nCreate a new layer with dynamic dispatch.\nGet current operator’s limit. Limit is usually the …\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir …\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir …\nOperate on error with map.\nFetch metadata of this entry.\nobject-store metrics\nName of entry. Name is the last segment of path.\nCreate a new Error with error kind and message.\nCreate a new operator with input builder.\nCreate a new http client in async context.\nPath of entry. Path is relative to operator’s root.\nWriter makes sure that every write is flushed.\nPresign an operation for read.\nPresign an operation for read option described in OpenDAL […\nPresign an operation for stat(head).\nPresign an operation for stat(head).\nPresign an operation for write.\nPresign an operation for write with option described in …\nMake sure all operation are constructed by normalized path:\nRead the whole path into a bytes.\nRead the whole path into a bytes with extra options.\nCreate a new reader which can read the whole path.\nCreate a new reader with extra options\nNotes\nRemove the path and all nested dirs and files recursively.\nremove will remove files via the given paths.\nRename a file from <code>from</code> to <code>to</code>.\nSend a request in async way.\nServices will provide builders to build underlying …\nSet permanent status for error.\nSet persistent status for error.\nSet source for error.\nSet temporary status for error.\nSink into writer.\nGet given path’s metadata.\nGet given path’s metadata with extra options.\nCreate a new operator from given scheme and map.\nAdd more context in error.\nSpecify the batch limit.\nUpdate error’s operation.\nWrite into inner writer.\nWrite bytes into path.\nWrite data with extra options.\nWrite multiple bytes into path.\nWrite multiple bytes into path with extra options.\nAdd concurrent request limit.\nAdd an immutable in-memory index for underlying storage …\nAdd log for every operations.\nAn opendal layer with local LRU file cache supporting.\nPlease refer to prometheus for every operations.\nRetryInterceptor is used to intercept while retry happened.\nAdd retry for temporary failed operations.\nAdd timeout for every operations to avoid slow or …\nAdd tracing for every operations.\nInsert keys from iter.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nInsert a key into index.\nEverytime RetryLayer is retrying, this function will be …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a new retry layer.\nCreate a new ConcurrentLimitLayer will specify permits\nCreate a new <code>TimeoutLayer</code> with default settings.\ncode originally from …\nSetting whether to output backtrace while unexpected …\nSetting the log level while expected error happened.\nSet factor of current backoff.\nSetting the log level while unexpected failure happened.\nSet io timeout for TimeoutLayer with given value.\nSet jitter of current backoff.\nSet max_delay of current backoff.\nSet max_times of current backoff.\nSet min_delay of current backoff.\nSet the retry interceptor as new notify.\nSet speed for TimeoutLayer with given value.\nSet timeout for TimeoutLayer with given value.\nAn opendal layer with local LRU file cache supporting.\nReturns true when the local cache contains the specific …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a <code>[LruCacheLayer]</code> with local file cache and …\nReturns the read cache statistics info …\nLocal read cache for files in object storage\nCache value for read file\nBlocking version of <code>invalidate_entries_with_prefix</code>.\nReturns true when the path of the file can be cached.\nReturns true when the read cache contains the specific …\nLocal file cache backend\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nInvalidate all cache items which key starts with <code>prefix</code>.\nLocal memory cache to track local cache files\nCreate a <code>ReadCache</code> with capacity in bytes.\nRead from a specific path using the OpRead operation. It …\nGenerate an unique cache key for the read path and range.\nRead the file from remote storage. If success, write the …\nRecover existing cache items from <code>file_cache</code> to <code>mem_cache</code>. …\nReturns the cache’s entry count and total approximate …\nContains the error value\nContains the success value\nPlease refer to prometheus for every operations.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nManages multiple object stores so that users can configure …\nAdds an object store to the manager.\nFinds an object store corresponding to the name.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new manager from the object store used as a …\nCache size in bytes\nCache entry number\nCache hit counter, no matter what the cache result is.\nCache miss counter\nObject store read error counter\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCapabilities\nAzure Storage Blob services support.\nPOSIX file system support.\nGoogle Cloud Storage services support.\nGoogle Cloud Storage services support.\nHTTP Read-only service support like Nginx and Caddy.\nConfig for Http service support.\nAliyun Object Storage Service (OSS) support\nAws S3 and compatible services (including minio, …\nConfig for Aws S3 and compatible services (including …\nSet access_key_id of this backend.\nSet access_key_id of this backend.\naccess_key_id of this backend.\nSet access_key_secret of this backend.\nSet account_key of this backend.\nThe account key of Azblob service backend.\nSet account_name of this backend.\nThe account name of Azblob service backend.\nAllow anonymous will allow opendal to send request without …\nAllow anonymous will allow opendal to send request without …\nAllow anonymous will allow opendal to send request without …\nSet temp dir for atomic write.\nSet maximum batch operations of this backend.\nSet maximum batch operations of this backend.\nSet maximum batch operations of this backend.\nThe maximum batch operations of Azblob service backend.\nSet maximum batch operations of this backend.\nset the container’s name\nSet bucket name of this backend.\nSet bucket name of this backend.\nbucket name of this backend.\nSet container name of this backend.\nThe container name of Azblob service backend.\nset the base64 hashed credentials string used for OAuth2\nset the credentials path of GCS.\nAdding a customed credential load for service.\nSpecify the customed token loader used by this service.\nSet the default storage class for GCS.\nSet default storage_class for this backend.\ndefault storage_class for this backend.\nDetect region of S3 bucket.\nDisable config load so that opendal will not load config …\nDisable config load so that opendal will not load config …\nDisable load credential from ec2 metadata.\nDisable load credential from ec2 metadata.\nDisable stat with override so that opendal will not send …\nDisable stat with override so that opendal will not send …\nOpenDAL requires all input path are normalized to make …\nEnable virtual host style so that opendal will send API …\nEnable virtual host style so that opendal will send API …\nSet encryption_algorithm of this backend.\nThe encryption algorithm of Azblob service backend.\nSet encryption_key of this backend.\nThe encryption key of Azblob service backend.\nSet encryption_key_sha256 of this backend.\nThe encryption key sha256 of Azblob service backend.\nSet endpoint of this backend\nset the endpoint GCS service uses\nSet endpoint for http backend.\nSet endpoint of this backend.\nSet endpoint of this backend.\nThe endpoint of Azblob service backend.\nendpoint of this backend\nendpoint of this backend.\nSet external_id for this backend.\nexternal_id for this backend.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nfrom_connection_string will make a builder from connection …\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nset password for http backend\npassword of this backend\nSet the predefined acl for GCS.\nSet a endpoint for generating presigned urls.\nRegion represent the signing region of this endpoint. This …\nRegion represent the signing region of this endpoint. This …\nSet role_arn for this backend.\nrole_arn for this backend.\nSet root of this backend.\nSet root for backend.\nset the working directory root of backend\nSet root path of http backend.\nSet root of this backend.\nSet root of this backend.\nThe root of Azblob service backend.\nroot of this backend\nroot of this backend.\nSet sas_token of this backend.\nThe sas token of Azblob service backend.\nset the GCS service scope\nSet secret_access_key of this backend.\nsecret_access_key of this backend.\nSet temporary credential used in AWS S3 connections\nsecurity_token (aka, session token) of this backend.\nSet server_side_encryption for this backend.\nSet server_side_encryption for this backend.\nserver_side_encryption for this backend.\nSet server_side_encryption_aws_kms_key_id for this backend\nserver_side_encryption_aws_kms_key_id for this backend\nSet server_side_encryption_customer_algorithm for this …\nserver_side_encryption_customer_algorithm for this backend.\nSet server_side_encryption_customer_key for this backend.\nserver_side_encryption_customer_key for this backend.\nSet server_side_encryption_customer_key_md5 for this …\nSet server_side_encryption_customer_key_md5 for this …\nSet server_side_encryption_key_id for this backend.\nEnable server side encryption with aws managed kms key\nEnable server side encryption with customer key.\nEnable server side encryption with customer key.\nEnable server side encryption with customer managed kms key\nEnable server side encryption with s3 managed key\nSet the GCS service account.\nset bearer token for http backend\ntoken of this backend\nset username for http backend\nusername of this backend\nTemp folder for object store test\nTest s3 config from environment variables\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns s3 test config, return None if not found.\nCollect all entries from the Lister.\nJoin two paths and normalize the output dir.\nPush <code>child</code> to <code>parent</code> dir and normalize the output path.\nModified from the <code>opendal::raw::normalize_root</code>\nMake sure all operation are constructed by normalized path:\nAttaches instrument layers to the object store.")